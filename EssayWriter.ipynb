{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FP-GWbYolMq"
      },
      "source": [
        "# Essay Writer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfahGH1cieIP"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "import os\n",
        "\n",
        "openai_api_key = userdata.get('OpenAIAPI')\n",
        "tavily_api_key = userdata.get('TavilyAPI')\n",
        "langsmith_api_key = userdata.get('LangSmithAPI')\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "os.environ[\"TAVILY_API_KEY\"] = tavily_api_key\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = langsmith_api_key\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"essay-writer\"\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"      # enables traces to LangSmith\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"   # optional newer trace flag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS2qgctCooqH"
      },
      "source": [
        "## Defining the AgentState and the Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR16UcYZo9eJ"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain_openai langchain_core langgraph tavily-python pydantic langsmith -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8siEoGZonhq"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model='gpt-4o-mini', temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyjv1GZho6C0"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, List, Annotated\n",
        "\n",
        "# Creating a class for the agent state\n",
        "class AgentState(TypedDict):\n",
        "    task: str\n",
        "    plan: str\n",
        "    draft: str\n",
        "    critique: str\n",
        "    content: List[str]\n",
        "    revision_number: int\n",
        "    max_revisions: int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcY3aZjQpHFq"
      },
      "outputs": [],
      "source": [
        "# Defining the planning prompt\n",
        "PLAN_PROMPT = '''You are an expert writer tasked with writing a high level outline of an essay.\n",
        "Write such an outline for the user provided topic.\n",
        "Give an outline of the essay along with any relevant notes or instructions for the sections.'''\n",
        "\n",
        "# defining the prompt that will be used by the agent that's doing research after the planning step\n",
        "# given a plan, it will generate some queries and pass them to Tavily\n",
        "RESEARCH_PLAN_PROMPT = '''You are a researcher charged with providing information that can be used when writing the following essay.\n",
        "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.'''\n",
        "\n",
        "# Defining the writer prompt\n",
        "WRITER_PROMPT = '''You are an essay assistant tasked with writing excellent 5-paragraph essays.\n",
        "Generate the best essay possible for the user's request and the initial outline.\n",
        "If the user provides critique, respond with a revised version of your previous attempts.\n",
        "Utilize all the information below as needed:\n",
        "\n",
        "------\n",
        "\n",
        "{content}'''\n",
        "\n",
        "# Defining the reflection prompt\n",
        "REFLECTION_PROMPT = '''You are a teacher grading an essay submission.\n",
        "Generate critique and recommendations for the user's submission.\n",
        "Provide detailed recommendations, including requests for length, depth, style, etc.'''\n",
        "\n",
        "# Defining the research critique prompt\n",
        "RESEARCH_CRITIQUE_PROMPT = ''''You are a researcher charged with providing information that can \\\n",
        "be used when making any requested revisions (as outlined below).\n",
        "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBKoPeo7pquY"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "\n",
        "class Queries(BaseModel):\n",
        "    queries: List[str]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To9WFA_KpxMG"
      },
      "outputs": [],
      "source": [
        "# Importing and instantiating a tavily client\n",
        "from tavily import TavilyClient\n",
        "import os\n",
        "\n",
        "tavily = TavilyClient()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i63FVxQU5KHP"
      },
      "source": [
        "# Implementing the Agents and the Nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS1oIB-_p2Rq"
      },
      "outputs": [],
      "source": [
        "# Creating the planning node\n",
        "def plan_node(state: AgentState):\n",
        "    messages = [\n",
        "        SystemMessage(content=PLAN_PROMPT),\n",
        "        HumanMessage(content=state['task'])\n",
        "    ]\n",
        "    response = model.invoke(messages)\n",
        "    return {\"plan\": response.content}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRBgczWt5epR"
      },
      "outputs": [],
      "source": [
        "# Creating the reseach_plan_node\n",
        "# It generates research queries based on a given task and retrieves relevant content using those queries\n",
        "def research_plan_node(state: AgentState):\n",
        "    queries = model.with_structured_output(Queries).invoke([    # with_structured_output ensures the model's response is structured with query's Pydantic model (Queries)\n",
        "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
        "        HumanMessage(content=state['task'])\n",
        "    ])\n",
        "    content = state.get('content', [])\n",
        "\n",
        "    for q in queries.queries:\n",
        "        response = tavily.search(query=q, max_results=2)\n",
        "        for r in response['results']:\n",
        "            content.append(r['content'])\n",
        "    return {\"content\": content}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUqqzWLd5fAP"
      },
      "outputs": [],
      "source": [
        "# Creating the generation node\n",
        "def generation_node(state: AgentState):\n",
        "    content = \"\\n\\n\".join(state['content'] or [])\n",
        "\n",
        "    user_message = HumanMessage(\n",
        "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\"\n",
        "        )\n",
        "\n",
        "    messages = [\n",
        "        SystemMessage(\n",
        "            content=WRITER_PROMPT.format(content=content)\n",
        "        ),\n",
        "        user_message\n",
        "        ]\n",
        "\n",
        "    response = model.invoke(messages)\n",
        "\n",
        "    return {\n",
        "        \"draft\": response.content,\n",
        "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ph6I_Ec7jP4"
      },
      "outputs": [],
      "source": [
        "# Creating the reflection node\n",
        "def reflection_node(state: AgentState):\n",
        "    messages = [\n",
        "        SystemMessage(content=REFLECTION_PROMPT),\n",
        "        HumanMessage(content=state['draft'])\n",
        "    ]\n",
        "    response = model.invoke(messages)\n",
        "    return {\"critique\": response.content}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiFL2b8_8Fcp"
      },
      "outputs": [],
      "source": [
        "# Creating the research critique node\n",
        "def research_critique_node(state: AgentState):\n",
        "    queries = model.with_structured_output(Queries).invoke([\n",
        "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
        "        HumanMessage(content=state['critique'])\n",
        "    ])\n",
        "    content = state['content'] or []\n",
        "    for q in queries.queries:\n",
        "        response = tavily.search(query=q, max_results=2)\n",
        "        for r in response['results']:\n",
        "            content.append(r['content'])\n",
        "    return {'content': content}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1re0GSb_T6m"
      },
      "outputs": [],
      "source": [
        "# Defining the conditional edge\n",
        "def should_continue(state):\n",
        "    if state['revision_number'] > state['max_revisions']:\n",
        "        return END\n",
        "    return 'reflect'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icZmqEQ3_jir"
      },
      "outputs": [],
      "source": [
        "builder = StateGraph(AgentState)\n",
        "\n",
        "# Adding nodes to the graph\n",
        "builder.add_node('planner', plan_node)\n",
        "builder.add_node('generate', generation_node)\n",
        "builder.add_node('reflect', reflection_node)\n",
        "builder.add_node('research_plan', research_plan_node)\n",
        "builder.add_node('research_critique', research_critique_node)\n",
        "\n",
        "# Setting the entry point of the state graph\n",
        "builder.set_entry_point('planner')\n",
        "\n",
        "# Adding the conditional edge\n",
        "builder.add_conditional_edges(\n",
        "    'generate',\n",
        "    should_continue,\n",
        "    {END: END, 'reflect': 'reflect'}\n",
        ")\n",
        "\n",
        "# Adding regular edges\n",
        "builder.add_edge('planner', 'research_plan')\n",
        "builder.add_edge('research_plan', 'generate')\n",
        "\n",
        "builder.add_edge('reflect', 'research_critique')\n",
        "builder.add_edge('research_critique', 'generate')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fuokg0OWAUuP"
      },
      "outputs": [],
      "source": [
        "!pip install -q langgraph-checkpoint-sqlite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pIkW5_qBac3"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = SqliteSaver.from_conn_string(':memory:')\n",
        "\n",
        "graph = builder.compile(checkpointer=MemorySaver())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCWp-kIHBdI3"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFcX3PT4BgZt"
      },
      "outputs": [],
      "source": [
        "thread = {'configurable': {'thread_id': '1'}}\n",
        "task = 'Nvidia Blackwell AI chip'\n",
        "\n",
        "prompt = {\n",
        "    'task': task,\n",
        "    'max_revisions': 2,\n",
        "    'revision_number': 1,\n",
        "}\n",
        "\n",
        "events = graph.stream(prompt, thread)\n",
        "for e in events:\n",
        "    print(e)\n",
        "    print('-' * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrBm9ogPBrX3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
